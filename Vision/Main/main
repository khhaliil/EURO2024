import cv2
import cv2.aruco as aruco
import numpy as np
from save_data import save_frame
from save_data import Calculate_homography
from save_data import pixel_to_mm
from Kalman import get_measurements,predict_future_positions_kalman
import os 
import sys
from save_data import Button, save_frame
import Model

sys.path.append(r'C:\Users\MSI\Desktop\EURO2024')  # Replace with the absolute path to EURO directory
###############################################################################
gray_output = False
BLUE_TEAM_RANGE = [1,2,3,4, 5]
YELLOW_TEAM_RANGE = [6,7,8,9, 10]
yolo_model = Model.initialize_yolo(r"C:\Users\MSI\Desktop\EURO2024\Vision\Data\Model V0\runs\detect\train6\weights\best.pt")

color_to_track=YELLOW_TEAM_RANGE

def switch_team(team_color):
    global current_team_range
    if team_color.lower() == 'blue':
        current_team_range = BLUE_TEAM_RANGE
    elif team_color.lower() == 'yellow':
        current_team_range = YELLOW_TEAM_RANGE
    else:
        print(f"Unknown team color: {team_color}")

###############################################################################

# calib_data_path = r"Vision\calibration\Calib_matrix\MultiMatrixXiaomi.npz"
# calib_data = np.load(calib_data_path)
# cameraMatrix = calib_data['camMatrix']
# distCoeffs = calib_data['distCoef']

marker_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_250)
aruco_params = aruco.DetectorParameters()

Calculate_homography_manually = False
homography_calculated= False
homography_matrix_path = r"C:\Users\MSI\Desktop\EURO2024\Tools\homography_matrix.npz"

def load_homography_matrix(path):
    try:
        with np.load(path) as data:
            return data['homography_matrix']
    except KeyError:
        print(f"'homography_matrix' not found in {path}")
        return None
    except IOError:
        print(f"Could not read file: {path}")
        return None

homography_matrix = load_homography_matrix(homography_matrix_path)
print(homography_matrix)
map_corners_3d = np.float32([[0, 0], [2, 0], [2, 3], [0, 3]])
save_button = Button(10, 10, 60, 30, "Save")

global capture_mode
capture_mode = False

bird_view_done= False
# Set the mouse callback function for your top_down window
cv2.namedWindow('Top-Down View')

def click_event(event, x, y, flags, param):
    global capture_mode

    # First, check for button click
    if event == cv2.EVENT_LBUTTONDOWN:
        if save_button.check_click(x, y):
            save_frame(img_top_down, prefix='top_down', manual_save=True)
            return

        # If not a button click, check for capture mode
        if capture_mode:
            captured_x, captured_y = x, y
            print("Captured real coordinates",pixel_to_mm(captured_x, captured_y))
            print(f"Captured pixel coordinates: {captured_x}, {captured_y}")
            capture_mode = False

def button_click_event(event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN:
        if save_button.check_click(x, y):
            save_frame(img_top_down, prefix='top_down', manual_save=True)

cv2.setMouseCallback('Top-Down View', click_event)
cv2.namedWindow('Button Window')
cv2.setMouseCallback('Button Window', button_click_event)



mapx = 2
mapy = 3
cap = cv2.VideoCapture(3)
cv2.namedWindow("Trackbars")

def nothing(x):
    pass

# Create trackbars for adjusting parameters
cv2.createTrackbar("Marker Length", "Trackbars", 10, 20, nothing)  # Range from 0.1m to 0.2m
cv2.createTrackbar("X Aruco", "Trackbars", 516, 1000, nothing)  # Example range
cv2.createTrackbar("Y Aruco", "Trackbars", 755, 1000, nothing)
button_window_img = np.zeros((100, 200, 3), dtype=np.uint8)

while True : 

    ret,img = cap.read()
    if not ret :
        break 
    
    #img = cv2.flip(img, -1)
    if gray_output:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    img_top_down = img



    if homography_calculated == False:
        if homography_matrix is None or Calculate_homography_manually == True:
            corners, ids, rejected = aruco.detectMarkers(img, marker_dict, parameters=aruco_params)
            homography_matrix = Calculate_homography(corners,ids,img)
            # print("hhnfdj",homography_matrix)
            if homography_matrix is not None:
                Calculate_homography_manually = not Calculate_homography_manually
                homography_calculated = True
            else:
                print("Homography matrix calculation failed")
        else:
            print("loaded homography matrix from local")
            homography_calculated = True
            
    if homography_matrix is not None and not bird_view_done:
        try:
            map_corners_2d = cv2.perspectiveTransform(map_corners_3d.reshape(-1, 1, 2), homography_matrix)
                   
        except cv2.error as e:
            print(f"Error in perspective transform: {e}")
        #print (map_corners_2d)
    # Draw the projected corners on the image
        points = []
        for i in range(map_corners_2d.shape[0]):
            point = tuple(map_corners_2d[i, 0].astype(int))
            points.append(point)
        #cv2.circle(img, point, 10, (0, 255, 0), -1)
        #cv2.putText(img,str(i),point,cv2.FONT_HERSHEY_COMPLEX,1,(0, 255, 0),2)
        #print(img.shape)
        src_pts = np.array([points[1],points[0],  points[2], points[3]], dtype='float32')
        dst_pts = np.array([[0,0],[ 0,img.shape[0]],  [img.shape[1], 0], [ img.shape[1],img.shape[0]]], dtype='float32')
        M = cv2.getPerspectiveTransform(src_pts, dst_pts)
 # Warp the image to get the top-down view
        
        homography_calculated = True
        bird_view_done= not bird_view_done
    
  
    ennemy_robot_predictions = []   
    img_top_down = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))
    tags_to_track=color_to_track
    get_measurements(img_top_down,tags_to_track=tags_to_track,debug=False)


    for tag in tags_to_track:
        current_position, ennemy_robot_predictions = predict_future_positions_kalman(tag,debug=False)
        
        if current_position is not None:
            cv2.circle(img_top_down, (int(current_position[0]), int(current_position[1])), 5, (255, 0, 255), -1)
        
        
        if ennemy_robot_predictions is not None:
            for pos in ennemy_robot_predictions:
                x, y = int(pos[0]), int(pos[1])
                cv2.circle(img_top_down, (x, y), 4, (0, 0, 255), -1)
    



    save_button.draw(button_window_img)
    cv2.imshow('Button Window', button_window_img)


    img_top_down = Model.perform_detection(yolo_model, img_top_down)
    # Display the images
    cv2.imshow('Top-Down View', img_top_down)
    cv2.imshow('Marked Image', img)
    


    key = cv2.waitKey(1) & 0xFF
    if key == ord('s'):
        # Manual save
        save_frame(img_top_down, prefix='top_down', manual_save=True)
    else:
        # Automatic save every 10 seconds
        pass
        #save_frame(img_top_down, prefix='top_down', interval=12)
    if key == ord('g'):
            # Toggle capture mode
        capture_mode = not capture_mode
        if capture_mode:
            print("Capture mode activated. Click on the desired pixel.")
        else:
            print("Capture mode deactivated.")
    if key == ord('h'):
        # Toggle the Calculate_homography_manually flag
        Calculate_homography_manually = not Calculate_homography_manually
        homography_calculated= False
        bird_view_done = not bird_view_done
        if Calculate_homography_manually:
            print("Manual homography calculation mode activated.")
        else:
            print("Manual homography calculation mode deactivated.")
    if key == ord('q'):
        break
        
   
cap.release()
cv2.destroyAllWindows()
